{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca77c51f",
   "metadata": {},
   "source": [
    "# Io Persona v1.3 + ICP v1.0 — Installer Notebook\n",
    "\n",
    "This notebook helps you:\n",
    "\n",
    "1. Load the Io v1.3 persona config and Io–Ceven Collaborative Protocol (ICP v1.0)\n",
    "2. Build a combined `system` prompt\n",
    "3. (Optionally) test a call against an OpenAI-compatible API, such as OpenAI or LM Studio\n",
    "\n",
    "## File Expectations\n",
    "\n",
    "By default, this notebook expects the following files to be in the **same directory**:\n",
    "\n",
    "- `Io_v1_3_Config.json`\n",
    "- `Io_v1_3_Implementable_Spec.md` (optional, for reference)\n",
    "- `ICP_v1_0.md`\n",
    "- `ICP_v1_0.json` (optional, for structured reference)\n",
    "\n",
    "You can adjust the paths in the code cells if you place them elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef155a",
   "metadata": {},
   "source": [
    "## 1. Load Configs and Build System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689d9d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "BASE = Path('.')  # adjust if your config files live elsewhere\n",
    "\n",
    "io_cfg_path = BASE / 'Io_v1_3_Config.json'\n",
    "icp_md_path = BASE / 'ICP_v1_0.md'\n",
    "\n",
    "with io_cfg_path.open('r', encoding='utf-8') as f:\n",
    "    io_cfg = json.load(f)\n",
    "\n",
    "with icp_md_path.open('r', encoding='utf-8') as f:\n",
    "    icp_text = f.read()\n",
    "\n",
    "persona_prompt = io_cfg.get('system_prompt', '').strip()\n",
    "if not persona_prompt:\n",
    "    raise ValueError(\"Io config is missing 'system_prompt'.\")\n",
    "\n",
    "combined_system_prompt = (\n",
    "    persona_prompt\n",
    "    + '\\n\\n---\\n\\n'\n",
    "    + 'The following collaboration protocol with the user **Ceven** is in effect. '\n",
    "      'You must align your behavior to it while preserving safety policies:'\n",
    "    + '\\n\\n'\n",
    "    + icp_text.strip()\n",
    ")\n",
    "\n",
    "print(combined_system_prompt[:1000])  # preview first ~1000 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a802328",
   "metadata": {},
   "source": [
    "## 2. (Optional) Test with an OpenAI-Compatible Backend\n",
    "\n",
    "This cell assumes you have installed the `openai` Python package and have an API-compatible\n",
    "backend configured (OpenAI, LM Studio, etc.). Adjust the `base_url` and `model` as needed.\n",
    "\n",
    "If you are using LM Studio, you typically set `base_url` to something like\n",
    "`'http://localhost:1234/v1'` and provide a dummy `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3ffe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Configure your backend here\n",
    "MODEL = 'gpt-4.1-mini'  # or your local model id\n",
    "BASE_URL = None  # e.g. 'http://localhost:1234/v1' for LM Studio\n",
    "\n",
    "client_kwargs = {}\n",
    "if BASE_URL is not None:\n",
    "    client_kwargs['base_url'] = BASE_URL\n",
    "\n",
    "client = OpenAI(**client_kwargs)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": combined_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"Hey Io, please confirm that you are running with Io v1.3 + ICP v1.0.\"},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0c9eb",
   "metadata": {},
   "source": [
    "## 3. Next Steps\n",
    "\n",
    "- Commit this notebook and the config files into your GitHub repo using the suggested structure.\n",
    "- Use the combined system prompt in any LLM client where you want to instantiate Io.\n",
    "- Optionally, create additional notebooks that:\n",
    "  - Test specific modes (Executor / Explorer / Challenger / Synthesizer / Visionary)\n",
    "  - Benchmark responses across different models or providers\n",
    "  - Log and review Io's behavior for consistency with the Io v1.3 Blueprint and ICP v1.0."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
